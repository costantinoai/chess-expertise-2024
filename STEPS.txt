NOTE: to help with the BIDS conversion of fMRI data, it is advisable to NOT collect
	nifti (.nii) files at the scanner, but rather DICOM files for each (NOT PAR/REC)
	run. This will take longer and add an extra conversion step, but it will ensure that 
	all the files will be converted properly into BIDS format. Unfortunately, some BIDS
	fields in the sidecar JSON files will be empty anyways: this is a limitation of the
	Philip scanner, and not a limitation of the conversion tools. More info on the 
	Philips DICOM conversion can be found here: 

	https://github.com/rordenlab/dcm2niix/tree/master/Philips
	https://github.com/rordenlab/dcm2niix/tree/master/PARREC

- BEH:
    NOTE: the input files should be named '*exp.mat', '*loco1.mat', '*loco2.mat' 

    1. utils -> behToBIDS -> expBehToBIDS.m	
    2. change 'dirname' to the directory where the MAT files are located
    3. run
    4. repeat the steps above for loc1BehToBIDS.m and loc2BehToBIDS.m
    5. move the TSV files in the sub-xx/func/ BIDS folder
    
    NOTE: The steps above should create one TSV for each MAT file. The naming 
    convention follows the BIDS format. Make sure that each file has at least
    3 columns representing: onset  duration  trial_type

- ET:
    PRE-REQUISITE: to convert EDF files into more easy-to-read ASC files, you
    need to install the EyeLink Developers Kit / API. More info and how-to:
    https://www.sr-research.com/support/thread-13.html

    1. Run ET script to convert to ASC in BIDS format
    NOTE: BEP020 has not been approved yet. Not sure if the events 
    MSG should be included here or not.
    
- fMRI:
	#################################################### perhaps not needed? we are going to use MATLAB
	0. create conda environment from fMRI_env.yaml
		--> conda env create -f <path-to-fMRI_env.yaml>
	NOTELO: this step is not yet done on the LBP comp as we need to install anaconda first
	####################################################
	
	1. Convert DICOM to BIDS (nifti):
		- PREREQ: 
			- dcmi2nii 
			- Raw data should be organized as : /sourcedata/sub-<xx>/fmri/dicom
			- MATLAB
			
	1a. Download dicm2nii from -> https://github.com/xiangruili/dicm2nii ->  unzip and add to Matlab path. 

	1b. Open Matlab. Type anonymize_dicm in console. Enter and it will ask you to select the folder where the files are and the folder in which you want to save it:
	/sourcedata/sub-<xx>/fmri/dicom_Anon

	1c. Run the dicm2nii matlab function from the unzipped file. Just write dicm2nii in the command window. Then a pop up will appear: select DICOM folder (Dicom_Anon. files) and result folder 		(Dicom_Converted). Untick compress box and make sure you select save json file. Start conversion. Pop up appears: subject: (only number of subject e.g. 01). Type: func (t2 scans) and anat (t1 	scans). Under modality we need task-{name of the task}_run-{number of run}_bold e.g. task-exp_run-2_bold. Modality for anatomical scans is T1W. This pop up will appear for each run of the fMRI 	sequence.
	At the end of this process we have a new folder called dicom_converted structured as follow:
		dicom_converted-|
				|- sub-01
				  |- anat
				    |- sub-01_T1w.json
				    |- sub-01_T1w.nii.gz
				  |- func
				    |- sub-01_task-exp_run-1_bold.json
				    |- sub-01_task-exp_run-1_bold.nii.gz
				    [...]
				  |- dcmHeaders.mat
				|- participants.tsv
				
Copy your sub-01 folder from dicom_converted into the BIDS folder (make a new one if you don't have one)

NOTELo: The pop up only appeared with the first participant and then does it automatically. This is quite annoying as it never gets the participant number right so you have to afterwards manually go in and change it. It also only worked when providing it with (enhanced) DICOM files. 



	It will just validate one of these files which will have generated the participants.tsv file and also 			the .json file which you will need. 
	For the json file: 

	If “PhaseEncodingDirection”: j? Set it to j.
	
	In the root BIDS folder also create a dataset_description.json file. 
	Here is an example: 

{
  "Name": "Chess experiment",
  "BIDSVersion": "1.9.9",
  "DatasetType": "raw",
  "License": "CC0",
  "Authors": [
    "Andrea Costantino",
    "Laura Van Hove"
  ],
  "Acknowledgements": "",
  "HowToAcknowledge": "",
  "Funding": [""],
  "EthicsApprovals": [""],
  "ReferencesAndLinks": [""],
  "DatasetDOI": ""
}


	2. Validate the BIDS directory (and solve errors). You may get some warnings about nonBIDS files, just ignore these. 
		- https://bids-standard.github.io/bids-validator/
	
	#################################################### this step is not needed, as we won't run freesurfer (we do not need surface data)	
	3. run FastSurfer recon-all routine (skip if you don't  have a GPU machine, or you want to run normal FreeSurfer with fMRIprep. NOTE: FastSurfer takes less than a minute, as opposed to 15h with FreeSurfer)
	
		- PREREQ: install docker desktop (--> https://docs.docker.com/desktop/install/ubuntu/)
			  nvidia-docker (--> https://developer.nvidia.com/blog/nvidia-docker-gpu-server-application-deployment-made-easy/), 
			  download FreeSurfer license, install wsl (windows only as it is the subsystem for linux)
			
			--> check if docker sees the gpu. If in Windows: Open wsl and write following command: sudo docker run --rm --gpus all nvidia/cuda:12.0.1-base-ubuntu20.04 nvidia-smi 
			    (cuda:12.0.1 must correspond to your cuda drivers version, and ubuntu20.04 to your ubuntu version. you can check theCUDA drivers version by running 'nvidia-smi' in a linux/wsl 				terminal). You give password of LBP computer
			--> This command will output: A table which shows you cud version and the GPUs. e.g. of a GPU is NVIDIA GeForce RTX 3070. Make sure there is at least one. If not, reinstall Nvidia 				docker. 
			
		- (on Andrea's ubuntu laptop) sudo docker run --gpus all -v /media/costantino_ai/T7/fMRI_chess/data/BIDS:/data -v /media/costantino_ai/T7/fMRI_chess/data/BIDS/derivatives/FastSurfer:/			output -v /media/costantino_ai/T7/fMRI_chess/misc:/fs_license --rm --user $(id -u):$(id -g) deepmi/fastsurfer:latest --fs_license /fs_license/license.txt --t1 /data/sub-00/anat/			sub-00_T1w.nii --sid sub-00 --sd /output --parallel
		


		- (LBP computer) docker run --gpus all -v /mnt/c/Andrea/data/BIDS_Laura:/data -v /mnt/c/Andrea/data/BIDS_Laura/derivatives/fastsurfer:/output -v /mnt/c/Andrea/data/scripts\ and\ codes:/fs_license --rm --user $(id -u):$(id -g) deepmi/fastsurfer:latest --fs_license /fs_license/license.txt --t1 /data/sub-00/anat/sub-00_T1w.nii --sid sub-00 --sd /output --device cuda:0 -- surfreg --parallel
			

		After the first -v: write path of where your BIDS folder is 
		The next -v: write path to where you want the output to be saved 
		the next -v is path of where the license is stored

		NOTE: If you are using wsl for Windows, the path of the C-drive is going to be /mnt/c/
	
		FIXME: at the moment it looks like docker is using the wrong GPU on the LBP machine (Intel GPU vs. the NVIDIA one). Look into this before next subj.
			NOTE: if you are running the command from wsl and you want to select a folder in windows, you need to change 'C:/' to '/mnt/c/'
			NOTE: if you use wsl, you may need to change all the backslash '\' in a folder path into '/'
			NOTE: if you have spaces ' ' in your folder path, you need to put a backslash '\' before each space in the folder path (e.g., "/mnt/c/folder with space/" -> "/mnt/c/folder\ with\ space"), otherwise wsl will not recognise the fuul folder (it will stop at the first space)
			
	####################################################

4. Run fMRIprep (it takes about 2h)
	% NOTE: if you didn't run fastsurfer beforehand, delete the options --fs-subjects-dir and --fs-no-reconall
	
		docker run -ti --rm \
		  -v /data/projects/chess/data/BIDS:/data:ro \
		  -v /data/projects/chess/data/out:/out \
		  -v /data/projects/chess/misc/license.txt:/opt/freesurfer/license.txt \
		  nipreps/fmriprep:23.1.3 /data /out/fmriprep participant \
		  --skip-bids-validation \
		  --work-dir /out/fmriprep_temp \
		  --output-spaces MNI152NLin2009cAsym:res-2 anat \
		  --fs-no-reconall \
		  --fd-spike-threshold 0.5 \
		  --ignore slicetiming \
		  --bold2t1w-dof 9 \
		  --participant_label 04

			%Note: An explanation for all the flags -- etc. can be found on fmriprep.org/en/stable/usage.html#command-line-arguments
			%Note: the first -v is the bids folder, the second v is output folder, the third v is the free surfer licence path. 

			%Note: This specified output folder created a folder in Andrea called data_OUT, put this in correct location in the derivatives of your BIDS folder
			%TODO: Look into problem with either fastsurfer or fmriPrep, but we think with fastsurfer as it took much longer when using the LBP comp and the output files differ. E.g. when 			clicking on derivatives -  fastsurfer  - labels, Andrea has 4 items and I have 93. In the adjacent MRI folder he has 34 and I have 40 items., etc…
			
	5. Run GLM in SPM
		- move your events files into BIDS/derivatives/fmriprep/sub-xx/func
		- TODO: look at my prev scripts to SPM batch and load confounds

When running GLM in SPM (“by hand") after steps 1-5

	SMOOTHING THE LOCALISER FILES
1.	Select the files which contain _space-MNI152NLin2009cAsym*_desc-preproc_bold.nii and save them in another folder called funcneeded
2.	gunzip the files using gunzip(‘*.gz’) in Matlab for this folder
3.	select localiser 1 files (2 as we had 2 runs) and then select ALL frames
4.	click on smooth and put as settings fwhm = [4 4 4] and smooth.prefix = smooth_
5.	save batch and run

	MODEL LOC 1 (follow same steps for loc2)
General note: remember to specify model, review model, estimate , results

•	Make a directory in matlab by going to console and writing mkdir ‘nameofdir’
•	Units for design = seconds
•	Interscan interval = 2
•	Mcirotime resolution = 60 microtime onset = 30
•	use the localiser 1 run 1 events.tsv file and filter the timings and durations for each condition and save as a txt file containing 2 columns with no headings 	(onset, duration)
	when using these files, go to the matlab terminal and use the following command e.g. for faces: FacesRun1 = importdata('Faces_run1.txt');
	FacesRun1(:,1) You will need to copy and paste these timings in the onset section of the corresponding condition tab under your fMRI model specification

•	You will also need to add in multiple regressor file for each run (which are the nuisance regressors). Use the sub-00_task-loc1_run-1_desc-confounds_timeseries files for each run and task. So make 	a new txt file for each run and task with the following regressor columns: global signal (first column), trans x, trans y, trans z, rot x, rot y, rot z and the non_steady columns. We 	also want to 	use the framewise displacement info. Therefore in the timeseries file add another column after framewise displacement and add excel function if ( = IF (select the square of the framewise 		displacement column) >0.5 , 1, 0). When copying this column make sure that it is copying the values and not the function so use: paste special – as values

•	After having specified and reviewed the model, you estimate the model (click on estimate -> select the SPM.mat folder and change write residuals to yes and run. 
•	Click on results -> select the SPM file and then make your contrasts of interest. Click on define new contrasts, give it a name and write the contrast you are interested in using 1, -1 and 0
•	Apply masking: none, set threshold at 0.001 and look at results 


EXPERIMENTAL TASK (not "by hand" but via scripts)

•	In test - analysis - func (on GITHUB) open the SPM_GLM_exp_checkmateLo.m file. Change the fMRIPrepPath to the acyl fMRIPrepPath and change OutRoot to an output folder of your choice. 
•	Run the script. It will be creating the SPM.mat file and the beta files for each stimulus i.e. chess position (+ a beta file for each nuisance regressor) for each experimental run. These will be 	located in your selected output folder - GLM - sub-XX - exp
•	Open the MVPAMAYscript in test - analysis - CosmoMVPA (GitHub) and change DataDir to folder in which your SPM.mat file you just created is located in. If working on Mac, make sure you add a / to 	the end of location
•	Select your ROI directory, i.e. the location where you have stored your created ROIs masks. 	
•	IN ROIs, select which ROIs you want to include in analysis
•	Under subjects fill in which sub numbers you are including in analysis
•	As output you will obtain three excel files. The first depicts a matrix on how well lda can classify between checkmate and non-checkmate on average per fold for each pairwise condition. It also 	provides some additional information like  amount of voxels included in the analysis (data_size) and also how well the classifier was at distinguishing between checkmate and non-checkmate stimuli.
	The second Excel document depicts a matrix which shows the average distance between each pairwise compared conditions, using the ldc function which calculates the cross-validated distance along 	the linear discriminant (this is equivalent to the cross-validated mahalanobis distance.) The third excel file is the same but with the value rescaled to be between 0 and 1. 
•	The script also permits you to make a heat map of the matrices. 



Note on Kanwisher masks problem: 
Instead of downloading the nifty files from their site (https://web.mit.edu/bcs/nklab/GSS.shtml) I now downloaded the files above which are in .hdr or .img format. The face parcel and the scene parcel contain more than just the FFA and the PPA so I only selected the left and right FFA and left and right PPA from these parcels. Object parcel contains just left and right LOC so I took both of these. To convert these .img files to matlab format, I opened marsbar -> build -> select image -> choose the .img one -> maintain as binary image: no -> apply function to image: no -> give it a name and save. Once it is in this format you can combine the left and right using marsbar transform. You can then export the combined files as a nifty and do all the normal steps.  You can find the latest masks I built on github under folder test - FinalVMasks. Caution as the masks which are further constrained with localiser or allvrest activations refer to the activations of sub-00.


			

		




		
    
    
